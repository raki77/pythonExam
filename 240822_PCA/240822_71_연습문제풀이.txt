

1. 머신러닝을 어떻게 정의할 수 있나?
    -> 머신러닝 = 인공지능 하위 집합. 학습과 개선을 위해 명시적으로 컴퓨터를
    프로그래밍 하는 대신, 컴퓨터가 데이터를 통해 학습하고 경험을 통해 개선 하도록
    훈련하는 것에 있다.
    머신러닝 프로그램은 적용을 통해, 개선되고 이용 가능한 데이터가 증가 할수록 더욱
    정확해 진다.



2. 머신러닝이 도움을 줄 수 있는 문제 유형 4가지
    -> 
     1) 분류 문제 (Classification Problems)
     2) 회귀 문제 (Regression Problems)
     3) 군집화 문제 (Clustering Problems)
     4) 차원축소 문제 (Dimensionality Reduction Problems)



3. 레이블된 훈련 세트란 무엇인가? (Labeled Training Set)

    1) 특징 (Feature) :
        각 데이터 포인트를 설명하는 속성 또는 변수들이다.
        
            예) 이미지 인식에서 특징은? 이미지 픽셀 값일수 있다.
            주택 가격 예측에서는 주택의 크기, 위치, 방의 수 등이 특징이 될 수 있다


    2) 레이블 (Label) :
        각 데이터 포인트에 대응되는 정답 값이다.

            예) 이미지 분류 문제에서는 이미지에 해당하는 클래스(개, 고양이)가 레이블이
            되고, 주택 가격 예측에서는 주택 실제가격이 레이블이 된다.


4. 가장 널리 사용되는 지도 학습 작업 2가지는?

    1) 분류 (Classification)
    2) 회귀 (Regression)


5. 보편적인 비지도 학습 작업 4가지는?
    
    1) 군집화 (Clustering)
        : 비슷한 특성을 가진 데이터 포인트들을 그룹으로 묶는 작업

    2) 차원 축소 (Dimensionality Reduction)
        : 많은 변수 또는 특징을 가진 데이터를 더 적은 수의 중요한 변수로 축소하는 작업

    3) 이상치 탐지 (Anomaly Detection)
        : 데이터에서 정상적인 패턴과 크게 다른 이상치 또는 이상 행위를 탐지하는 작업
    
    4) 연관 규칙 학습 (Association Rule Learning)
        : 데이터 포인트들 사이의 유의미한 연관성을 찾는 작업
  
  

6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 
    머신러닝 알고리즘을 사용할 수 있나?
    
    강화 학습?
        강화 학습은 에이전트(로봇)가 환경과 상호작용하면서 
        보상(Reward)을 최대화하는 행동을 학습하는 방식입니다. 
        이 경우, 로봇이 걸어가는 것은 일련의 행동을 통해 목표를 
        달성하는 문제로 볼 수 있습니다. 
        
        로봇은 걸어가는 과정에서 다양한 행동을 시도하고,
         그 행동이 좋은 결과(예: 넘어지지 않고 일정 거리를 이동)로 
         이어질 경우 보상을 받습니다.




7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나?
    군집화는 비슷한 특성을 가진 데이터 포인트들을 하나의 그룹(클러스터)로
    묶는 비지도 학습 기법

    주요 군집화 알고리즘 :
        
        1) K-평균 (K-Means)
            -> 데이터를 미리 정한 K개의 클러스터로 나누는 방법            
        
        2) 계층적 군집화 (Hierarchical Clustering)
            -> 데이터 포인트들을 계층 구조로 클러스터링하는 방법
        
        3) DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
            -> 밀도 기반 클러스터링 방법, 밀도가 높은 지역에서 클러스터를 형성,
               밀도가 낮은 지역의 데이터 포인트는 이상치(노이즈)로 간주
        
        4) Gaussian Mixture Models (GMM)
            -> 데이터를 여러 개의 가우시안 분포로 모델링하여 클러스터를 찾는 방법
            -> 각 클러스터가 가우시안 분포를 따름. 데이터 포인트가 특정 클러스터에 
            속할 확률을 계산.


8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나?

    지도 학습(Supervised Learning) 문제. 
        이유 : 
            1) 레이블된 데이터 : 
                스팸 감지에서 사용하는 데이터는 일반적으로 각 이메일에 '스팸' 또는 
                '스팸 아님' 이라는 레이블이 붙어 있다. 이 레이블된 데이터를 사용하여 
                머신러닝 모델을 학습 시키기 때문에 지도 학습의 범주에 속함.

            2) 학습 과정 :
                지도 학습 모델은 이메일의 특징과 해당 이메일의 레이블 간의 관계를 학습한다.
                이 과정을 통해, 새로운 이메일이 들어왔을 때, 그 이메일이 스팸인지 아닌지를
                예측할 수 있게 된다.

            분류 알고리즘: 
                로지스틱 회귀, 
                서포트 벡터 머신(SVM), 
                결정 트리, 
                랜덤 포레스트, 
                나이브 베이즈 등 다양한 분류 알고리즘이 스팸 감지에 사용될 수 있다.


9. 온라인 학습 시스템이 무엇인가??
    
    인공지능과 머신러닝에서 데이터를 한 번에 모두 학습하는 대신, 
    순차적으로 학습하는 방법이다. 
    온라인 학습은 새로운 데이터가 지속적으로 유입되는 환경에서 특히 유용하며, 
    모델이 점진적으로 학습하면서 지속적으로 업데이트 된다.

    특징 : 
        점진적 학습, 빠른 적응, 효율적인 메모리 사용, 실시간 학습
        온라인 학습 시스템은 데이터를 실시간으로 처리하고, 지속적으로 모델을 
        개선하는 데 강점을 가진 학습 방식으로, 변화하는 환경에서 특히 유용하다.



10. 외부 메모리 학습이 무엇인가?? External Memory Learning
    
    인공지능 시스템에서 대규모 데이터를 처리하거나 복잡한 작업을 수행하기 위해
    추가적인 메모리 구조를 사용하는 방법이다.

    모델이 단순히 현재 입력 만을 처리하는 것이 아니라, 과거의 정보나 외부에서 
    저장된 데이터를 기억하고, 필요할 때 참조할 수 있도록 한다.

    주요 개념 : 
        1) 확장된 기억력
        2) 동적 데이터 접근
        3) 대표적인 구조
        4) 적용 분야

    외부 메모리 학습은 인공지능 모델이 단순한 패턴 인식 이상의 작업을 
    수행할 수 있도록 돕는 중요한 기법이다.

    모델이 더 복잡한 문제를 해결하고, 더 많은 데이터를 효율적으로 처리할 수 
    있도록 하는 데 중요한 역할을 한다.



11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가?
    k-최근접 이웃 (k-Nearest Neighbors, k-NN) 알고리즘이다. 
    k-NN 알고리즘은 데이터 포인트의 유사도를 측정하여 예측을 수행하는 대표적인 방법이다



12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나?
    
    머신러닝 모델의 성능과 학습 과정을 조절하는 두 가지 중요한 요소 이다. 
    두 용어는 서로 다른 역할과 특성을 가지며, 각각의 정의와 차이점은 다음과 같다.

    모델 파라미터 (Model Parameters):
        모델 파라미터는 머신러닝 모델이 학습을 통해 자동으로 조정하는 값이다.
        모델이 입력 데이터와 예측 결과 간의 관계를 정의하는데 사용된다.
        예) 선형 회귀에서 기울기 (회귀계수)와 절편이 모델 파라미터이다.

    하이퍼 파라미터 (Hyperparameters):
        하이퍼파라미터는 모델의 학습 과정과 구조를 제어하는 설정 값으로, 
        모델 학습 전에 사람이 직접 설정해야 하는 값이다.
        하이퍼파라미터는 학습 알고리즘의 동작 방식을 정의하고, 모델의 학습속도,
        성능, 복잡성 등을 조절한다. 모델의 성능을 최적화하기 위해 적절한
        하이퍼 파라미터를 선택해야 한다.
        예) 학습률, K-NN, 신경망


13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는
 가장 일반적인 전략은 무엇인가? 예측은 어떻게 만드나??
    모델 기반 알고리즘이 찾는 것은 다음과 같다.
    1) 데이터의 내재적 패턴 또는 구조
    2) 적합한 모델 파라미터
    3) 예측 또는 의사결정의 규칙
    4) 모델의 일반화 성능


    모델 기반 알고리즘 (성공적 문제 해결을 위해서 사용되는 일반적 전략)
    1) 모델 학습 및 파라미터 최적화
    2) 교차 검증 및 모델 평가
    3) 하이퍼파라미터 조정
    4) 정규화 및 정규화 기법
    5) 데이터 전처리 및 특성 엔지니어링
    6) 모델 앙상블(Ensemble Learning)

    모델 기반 알고리즘은 성공적으로 문제를 해결하기 위해 모델 학습,
    파라미터 최적화, 교차 검증, 하이퍼파라미터 조정, 정규화, 데이터 전처리,
    모델 앙상블 등 다양한 전략을 사용한다. 
    
    이러한 전략들은 모델의 성능을 최적화하고, 데이터를 기반으로 유용한 예측을 수행하는 데 
    중요한 역할을 한다.

    예측은 어떻게 만드냐?
        모델 기반 알고리즘에서 예측을 만드는 과정은 모델을 학습하고, 
        학습된 모델을 사용하여 새로운 데이터에 대해 예측을 수행하는 단계로 나눌 수 있다.
        이 과정은 다음과 같은 주요 단계로 구성 된다.

        1) 데이터 준비
        2) 모델 선택
        3) 모델 학습
        4) 모델 평가
        5) 하이퍼파라미터 조정
        6) 예측 수행
        7) 모델 배포 및 모니터링

        예시
            회귀 문제 (예: 집값 예측): 
                데이터 준비: 집의 크기, 위치, 방의 수 등 관련 특성을 포함한 데이터 수집.
                모델 선택: 선형 회귀 모델 선택.
                모델 학습: 집값과 관련된 특성을 기반으로 선형 회귀 모델 학습.
                모델 평가: 교차 검증을 통해 모델의 성능 평가.
                하이퍼파라미터 조정: 정규화 파라미터 조정.
                예측 수행: 새로운 집의 특성으로 집값 예측.
                모델 배포: 웹 애플리케이션에 모델 배포.
        
        
            분류 문제 (예: 이메일 스팸 필터링): 
                데이터 준비: 스팸과 정상 이메일 데이터 수집.
                모델 선택: 나이브 베이즈 분류기 선택.
                모델 학습: 스팸과 정상 이메일의 패턴을 학습.
                모델 평가: 교차 검증을 통해 모델의 성능 평가.
                하이퍼파라미터 조정: 스무딩 파라미터 조정.
                예측 수행: 새로운 이메일이 스팸인지 아닌지 예측.
                모델 배포: 이메일 클라이언트에 모델 배포.




14. 머신러닝의 주요 도전 과제는 무엇인가?
    
    1) 데이터 관련 문제
        데이터 품질: 데이터가 불완전하거나 부정확할 때 모델의 성능이 저하됩니다. 결측값, 이상치, 
        노이즈가 있는 데이터는 모델 학습에 악영향을 미칠 수 있습니다.
        데이터 양: 충분한 양의 데이터를 확보하는 것이 중요합니다. 데이터가 부족하면 모델이 충분히 
        학습하지 못하거나 과적합(overfitting)될 수 있습니다.
        데이터 편향: 데이터가 특정 그룹에 대해 편향되어 있을 경우, 모델의 예측이 왜곡될 수 있습니다. 
        데이터의 균형을 맞추는 것이 필요합니다.
        데이터 라벨링: 라벨이 정확하지 않거나 일관되지 않을 경우, 지도 학습 모델의 성능에 영향을 미칩니다.
    
    2) 모델 관련 문제
        과적합(Overfitting)과 과소적합(Underfitting): 모델이 학습 데이터에 너무 잘 맞거나(과적합), 데이터의 패턴을 
        제대로 학습하지 못하거나(과소적합) 하는 문제가 발생할 수 있습니다. 
        이를 해결하기 위해 적절한 모델 복잡도와 정규화 기법이 필요합니다.
        모델 해석 가능성: 복잡한 모델(예: 딥러닝)은 해석하기 어렵고, 모델의 예측 결과를 이해하거나
        설명하기 어려울 수 있습니다.
        하이퍼파라미터 튜닝: 최적의 하이퍼파라미터를 찾는 것이 어려울 수 있으며, 
        하이퍼파라미터 조정은 시간과 자원을 많이 소모할 수 있습니다.
    
    3) 성능 문제
        모델의 일반화: 모델이 학습 데이터 외의 새로운 데이터에 대해 잘 일반화되지 않을 경우, 
        모델의 예측 성능이 떨어질 수 있습니다. 
        이는 충분한 검증과 테스트가 필요합니다.
        성능 평가: 적절한 성능 지표를 선택하고, 모델의 성능을 정확하게 평가하는 것이 중요합니다. 
        평가 지표는 문제의 특성에 맞게 선정해야 합니다.
    
    4) 계산 자원 및 효율성
        계산 비용: 대규모 데이터셋과 복잡한 모델은 많은 계산 자원을 소모하며, 
        이를 위한 인프라 비용이 발생할 수 있습니다.
        훈련 시간: 모델 학습에 소요되는 시간이 길어질 수 있으며, 
        특히 딥러닝과 같은 복잡한 모델에서는 훈련 시간이 상당할 수 있습니다.
    
    5) 데이터 프라이버시와 보안
        데이터 프라이버시: 개인정보를 포함한 데이터는 프라이버시와 관련된 법적 요구사항을 충족해야 하며, 
        데이터 보호와 관련된 정책을 준수해야 합니다.
        보안: 모델과 데이터를 보호하기 위해 보안 조치를 취해야 합니다. 
        악의적인 공격에 의해 모델이 왜곡되거나 데이터가 유출될 수 있습니다.
    
    6) 실시간 시스템과 배포
        실시간 예측: 실시간으로 예측을 제공하는 시스템에서는 높은 응답 속도와 낮은 지연 시간이 요구됩니다. 
        이를 위해 최적화된 모델과 효율적인 인프라가 필요합니다.
        배포 및 유지보수: 모델을 실제 환경에 배포하고, 지속적으로 모니터링하고 업데이트하는 과정이 필요합니다. 
        배포 후에도 모델의 성능이 저하되지 않도록 주기적으로 재훈련하고 유지보수해야 합니다.
    
    7) 윤리적 문제
        편향 및 공정성: 모델의 예측이 특정 집단에 대해 불공정하거나 편향될 수 있습니다. 
        모델의 결정이 공정하게 이루어지도록 하는 것이 중요합니다.
        책임성: 모델의 예측이 잘못된 경우, 책임의 소지가 있으며, 
        이를 해결하기 위한 책임 있는 AI 개발이 필요합니다.



15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화
성능이 나쁘다면 어떤 문제가 있나? 가능한 해결책 3가지는
무엇인가?
    1) 과적합 (Overfitting)
    2) 해결 방법
        정규화 (Regularization):
            L1 정규화 (Lasso): 가중치의 절대값 합에 패널티를 부여하여 모델의 복잡도를 줄입니다.
            L2 정규화 (Ridge): 가중치의 제곱합에 패널티를 부여하여 모델의 복잡도를 줄입니다.
            Elastic Net: L1 및 L2 정규화의 조합을 사용하여 복잡도를 조절합니다.
        교차 검증 (Cross-Validation): 
            모델의 일반화 성능을 평가하기 위해 교차 검증을 사용하여 데이터의 여러 부분에서 모델을
            테스트합니다. 이를 통해 과적합을 방지하고 모델의 성능을 더 정확하게 평가할 수 있습니다.
        드롭아웃 (Dropout): 
            신경망에서 학습 중 일부 뉴런을 무작위로 제거하여 과적합을 방지합니다. 이를 통해 모델의
            일반화 능력을 향상시킬 수 있습니다.
        데이터 증강 (Data Augmentation): 
            훈련 데이터의 양을 증가시키기 위해 데이터 증강 기법을 사용합니다. 이는 데이터의 다양성을 
            높이고 모델의 일반화 성능을 개선하는 데 도움을 줄 수 있습니다.
        모델 단순화 (Model Simplification): 
            모델의 복잡도를 줄이기 위해 더 간단한 모델을 선택하거나, 특성의 수를 줄이는 방식으로 
            모델의 복잡성을 낮출 수 있습니다.
        Early Stopping: 
            모델의 훈련을 조기에 종료하여 과적합을 방지합니다. 검증 데이터의 성능이 더 이상 개선되지 
            않을 때 학습을 중지합니다.
        정확한 하이퍼파라미터 조정: 
            하이퍼파라미터 조정을 통해 모델의 복잡도를 조절하고, 과적합을 방지할 수 있습니다. 
            그리드 탐색, 랜덤 탐색 등을 통해 최적의 하이퍼파라미터를 찾습니다.

    결론
        모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁜 경우, 
        과적합이 의심됩니다. 
        이를 해결하기 위해 정규화, 교차 검증, 드롭아웃, 데이터 증강, 모델 단순화,
        Early Stopping 등의 기법을 활용하여 모델의 일반화 성능을 개선할 수 있습니다. 
        이러한 방법들을 적절히 적용하여 모델이 새로운 데이터에 대해서도 우수한 성능을 
        발휘하도록 조정하는 것이 중요합니다.



16. 테스트 세트가 무엇이고 왜 사용해야 하나?
    테스트 세트 :
        머신러닝 모델의 성능을 평가하기 위해 사용되는 데이터셋
    
    1) 모델 일반화 성능 평가
        목표: 테스트 세트는 모델이 훈련 데이터 외의 새로운 데이터에 대해 어떻게 성능을 발휘하는지 평가합니다. 
        이는 모델이 실제 상황에서 잘 작동하는지를 확인하는 중요한 지표가 됩니다.
        설명: 모델이 훈련 데이터에 너무 적합(overfitting)되었는지, 
        아니면 새로운 데이터에도 잘 일반화되는지 테스트할 수 있습니다.
    
    2) 과적합 감지
        목표: 훈련 데이터에서의 성능이 높더라도, 테스트 세트에서의 성능이 낮을 경우 모델이 과적합되었을 가능성을 나타냅니다.
        설명: 과적합된 모델은 훈련 데이터의 노이즈와 패턴까지 학습하여, 새로운 데이터에서는 성능이 떨어질 수 있습니다.
         테스트 세트는 이러한 문제를 발견하고 모델을 개선하는 데 도움을 줍니다.
    
    3) 모델 비교 및 선택
        목표: 여러 모델이나 하이퍼파라미터 조합을 비교할 때, 테스트 세트를 사용하여 
        각 모델의 최종 성능을 평가하고 비교합니다.
        설명: 테스트 세트는 모델 선택 시 성능을 객관적으로 비교할 수 있는 기준을 제공합니다. 
        이를 통해 최상의 모델을 선택할 수 있습니다.
    
    4) 실제 배포 성능 예측
        목표: 테스트 세트에서의 성능은 모델이 실제 운영 환경에서 얼마나 잘 작동할지를 예측하는 데 도움을 줍니다.
        설명: 실제 데이터와 유사한 테스트 세트를 사용하여 모델의 실제 배포 성능을 가늠할 수 있습니다.




17. 검증 세트의 목적은 무엇인가??
    검증 세트(Validation Set) :
         머신러닝 모델을 개발할 때 사용되는 데이터의 일부
          모델의 하이퍼파라미터를 조정하고 모델의 성능을 평가하는 데 중요한 역할
          검증 세트는 모델 학습과정 중에 모델의 성능을 모니터링하고, 
          하이퍼파라미터 조정 및 모델 선택을 돕는 데 사용 된다.
    
    1) 하이퍼파라미터 조정
        목표: 모델의 하이퍼파라미터(예: 학습률, 정규화 강도, 은닉층의 수 등)를 최적화하여 
        모델의 성능을 향상시키는 것입니다.

    2) 모델 선택
        목표: 다양한 모델 또는 모델의 버전(예: 다른 알고리즘, 다른 네트워크 구조 등)을 비교하여 
        가장 적합한 모델을 선택하는 것입니다.

    3) 모델 조정 및 개선
        목표: 모델의 성능을 개선하고, 모델이 훈련 데이터에서 과적합되거나 과소적합되지 
        않도록 조정하는 것입니다.

    4) 과적합 방지
        목표: 훈련 데이터에 과적합되지 않도록 모델의 일반화 능력을 평가하고 조절하는 것입니다.

    5) 모델 평가 및 튜닝
        목표: 모델의 하이퍼파라미터와 성능을 평가하고, 모델을 튜닝하여 최상의 성능을 
        도출하는 것입니다.

    6) 모델의 안정성 확인
        목표: 모델의 성능이 데이터의 변동에 얼마나 민감한지를 확인하는 것입니다.




18. 훈련-개발 세트가 무엇인가? 언제 필요하고 어떻게
사용해야 하나?
    
    훈련-개발 세트(Training-Validation Set 또는 Training-Development Set)는 
    머신러닝 모델을 학습하고 조정할 때 사용하는 데이터셋으로, 
    모델의 성능을 향상시키기 위해 
    훈련 데이터와 검증 데이터 간의 역할을 분리하는 데 
    도움을 줍니다. 
    
    
    이 세트는 훈련과 검증을 보다 체계적으로 나누어 수행할 수 있게 하여
     모델의 성능을 개선하는 데 중요한 역할을 합니다.

    결론
        훈련-개발 세트는 머신러닝 모델의 학습과 평가 과정에서 중요한 역할을 하며,
         모델의 하이퍼파라미터 조정, 성능 평가, 과적합 방지 등 다양한 목적으로 사용됩니다.
          훈련 세트와 개발 세트를 명확히 분리하여 모델의 성능을 효과적으로 향상시키고,
           최종적으로 독립적인 테스트 세트에서 모델의 일반화 성능을 평가하는 것이 중요합니다.


19. 테스트 세트를 사용해 하이퍼 파라미터를 튜닝하면
어떤 문제가 생기나???

    1. 과적합 (Overfitting) 위험
        문제: 
            테스트 세트를 사용하여 하이퍼파라미터를 조정하면,
            테스트 세트에 모델이 과적합(overfitting)될 수 있습니다. 
            이 경우, 모델이 테스트 세트에 너무 잘 맞추어져서 새로운 
            데이터에 대한 일반화 능력이 떨어질 수 있습니다.

    2. 성능 평가의 왜곡
        문제: 
            하이퍼파라미터 조정 과정에서 테스트 세트를 반복적으로 사용하면, 
            테스트 세트의 성능 지표가 과대 평가(overestimated)될 수 있습니다.

    3. 신뢰할 수 없는 모델 선택
        문제: 
            테스트 세트를 하이퍼파라미터 튜닝에 사용하면, 
            모델 선택의 신뢰도가 떨어질 수 있습니다.

    4. 데이터 분할의 원칙 위배
        문제: 
            모델의 평가와 하이퍼파라미터 조정을 동일한 데이터셋에서 수행하면, 
            데이터 분할의 원칙이 위배됩니다.

    5. 모델의 실제 성능 예측 실패
        문제: 
            테스트 세트가 하이퍼파라미터 조정에 사용되면, 
            최종적으로 모델의 실제 성능을 정확히 예측하기 어렵습니다.