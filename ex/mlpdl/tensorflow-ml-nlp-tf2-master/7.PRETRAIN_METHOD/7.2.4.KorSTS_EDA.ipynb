{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer\n",
    "from gluonnlp.data import SentencepieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/KOR'\n",
    "TRAIN_STS_DF = os.path.join(DATA_IN_PATH, 'KorSTS', 'sts-train.tsv')\n",
    "train_data = pd.read_csv(TRAIN_STS_DF, sep='\\t', quoting = 3)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전체 train_data 개수: {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.Series(train_data['sentence1'].tolist() + train_data['sentence2'].tolist()).astype(str)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전체 문장 데이터의 개수: {}'.format(len(train_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('유일한 총 문장 수 : {}'.format(len(np.unique(train_set))))\n",
    "print('반복해서 나타나는 문장의 수: {}'.format(np.sum(train_set.value_counts() > 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에 대한 이미지 사이즈 선언\n",
    "# figsize: (가로, 세로) 형태의 튜플로 입력\n",
    "plt.figure(figsize=(12, 5))\n",
    "# 히스토그램 선언\n",
    "# bins: 히스토그램 값들에 대한 버켓 범위\n",
    "# range: x축 값의 범위\n",
    "# alpha: 그래프 색상 투명도\n",
    "# color: 그래프 색상\n",
    "# label: 그래프에 대한 라벨\n",
    "plt.hist(train_set.value_counts(), bins=50, alpha=0.5, color= 'r', label='word')\n",
    "plt.yscale('log', nonposy='clip')\n",
    "# 그래프 제목\n",
    "plt.title('Log-Histogram of sentence appearance counts')\n",
    "# 그래프 x 축 라벨\n",
    "plt.xlabel('Number of occurrences of sentence')\n",
    "# 그래프 y 축 라벨\n",
    "plt.ylabel('Number of sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('중복 최대 개수: {}'.format(np.max(train_set.value_counts())))\n",
    "print('중복 최소 개수: {}'.format(np.min(train_set.value_counts())))\n",
    "print('중복 평균 개수: {:.2f}'.format(np.mean(train_set.value_counts())))\n",
    "print('중복 표준편차: {:.2f}'.format(np.std(train_set.value_counts())))\n",
    "print('중복 중간길이: {}'.format(np.median(train_set.value_counts())))\n",
    "# 사분위의 대한 경우는 0~100 스케일로 되어있음\n",
    "print('제 1 사분위 중복: {}'.format(np.percentile(train_set.value_counts(), 25)))\n",
    "print('제 3 사분위 중복: {}'.format(np.percentile(train_set.value_counts(), 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "# 박스플롯 생성\n",
    "# 첫번째 파라메터: 여러 분포에 대한 데이터 리스트를 입력\n",
    "# labels: 입력한 데이터에 대한 라벨\n",
    "# showmeans: 평균값을 마크함\n",
    "\n",
    "plt.boxplot([train_set.value_counts()],\n",
    "             labels=['counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length = train_set.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_length, bins=200, range=[0,200], facecolor='r', density=True, label='train')\n",
    "plt.title(\"Normalised histogram of character count in sentence\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of characters', fontsize=15)\n",
    "plt.ylabel('Probability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장 길이 최대 값: {}'.format(np.max(train_length)))\n",
    "print('문장 길이 평균 값: {:.2f}'.format(np.mean(train_length)))\n",
    "print('문장 길이 표준편차: {:.2f}'.format(np.std(train_length)))\n",
    "print('문장 길이 중간 값: {}'.format(np.median(train_length)))\n",
    "print('문장 길이 제 1 사분위: {}'.format(np.percentile(train_length, 25)))\n",
    "print('문장 길이 제 3 사분위: {}'.format(np.percentile(train_length, 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.boxplot(train_length,\n",
    "             labels=['char counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_counts = train_set.apply(lambda x:len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_word_counts, bins=50, range=[0, 50], facecolor='r', density=True, label='train')\n",
    "plt.title('Normalised histogram of word count in sentence', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of words', fontsize=15)\n",
    "plt.ylabel('Prabability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장 단어 개수 최대 값: {}'.format(np.max(train_word_counts)))\n",
    "print('문장 단어 개수 평균 값: {:.2f}'.format(np.mean(train_word_counts)))\n",
    "print('문장 단어 개수 표준편차: {:.2f}'.format(np.std(train_word_counts)))\n",
    "print('문장 단어 개수 중간 값: {}'.format(np.median(train_word_counts)))\n",
    "print('문장 단어 개수 제 1 사분위: {}'.format(np.percentile(train_word_counts, 25)))\n",
    "print('문장 단어 개수 제 3 사분위: {}'.format(np.percentile(train_word_counts, 75)))\n",
    "print('문장 단어 개수 99 퍼센트: {}'.format(np.percentile(train_word_counts, 99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.boxplot(train_word_counts,\n",
    "             labels=['counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmarks = np.mean(train_set.apply(lambda x: '?' in x)) # 물음표가 구두점으로 쓰임\n",
    "math = np.mean(train_set.apply(lambda x: '[math]' in x)) # []\n",
    "fullstop = np.mean(train_set.apply(lambda x: '.' in x)) # 마침표\n",
    "capital_first = np.mean(train_set.apply(lambda x: x[0].isupper())) #  첫번째 대문자\n",
    "capitals = np.mean(train_set.apply(lambda x: max([y.isupper() for y in x]))) # 대문자가 몇개\n",
    "numbers = np.mean(train_set.apply(lambda x: max([y.isdigit() for y in x]))) # 숫자가 몇개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('물음표가있는 문장: {:.2f}%'.format(qmarks * 100))\n",
    "print('마침표를 포함한 문장: {:.2f}%'.format(fullstop * 100))\n",
    "print('첫 글자가 대문자 인 문장: {:.2f}%'.format(capital_first * 100))\n",
    "print('대문자가있는 문장: {:.2f}%'.format(capitals * 100))\n",
    "print('숫자가있는 문장: {:.2f}%'.format(numbers * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_token_counts = train_set.apply(lambda x:len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_bert_token_counts, bins=200, range=[0, 200], facecolor='r', density=True, label='train')\n",
    "plt.title('Normalised histogram of tokens count in sentence', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of tokens', fontsize=15)\n",
    "plt.ylabel('Prabability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장 tokens 개수 최대 값: {}'.format(np.max(train_bert_token_counts)))\n",
    "print('문장 tokens 개수 평균 값: {:.2f}'.format(np.mean(train_bert_token_counts)))\n",
    "print('문장 tokens 개수 표준편차: {:.2f}'.format(np.std(train_bert_token_counts)))\n",
    "print('문장 tokens 개수 중간 값: {}'.format(np.median(train_bert_token_counts)))\n",
    "print('문장 tokens 개수 제 1 사분위: {}'.format(np.percentile(train_bert_token_counts, 25)))\n",
    "print('문장 tokens 개수 제 3 사분위: {}'.format(np.percentile(train_bert_token_counts, 75)))\n",
    "print('문장 tokens 개수 99 퍼센트: {}'.format(np.percentile(train_bert_token_counts, 99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.boxplot(train_bert_token_counts,\n",
    "             labels=['counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_token_cased_counts = train_set.apply(lambda x:len(tokenizer.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_bert_token_cased_counts, bins=100, range=[0, 100], facecolor='r', density=True, label='train')\n",
    "plt.title('Normalised histogram of tokens count in sentence', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of tokens', fontsize=15)\n",
    "plt.ylabel('Prabability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장 tokens 개수 최대 값: {}'.format(np.max(train_bert_token_cased_counts)))\n",
    "print('문장 tokens 개수 평균 값: {:.2f}'.format(np.mean(train_bert_token_cased_counts)))\n",
    "print('문장 tokens 개수 표준편차: {:.2f}'.format(np.std(train_bert_token_cased_counts)))\n",
    "print('문장 tokens 개수 중간 값: {}'.format(np.median(train_bert_token_cased_counts)))\n",
    "print('문장 tokens 개수 제 1 사분위: {}'.format(np.percentile(train_bert_token_cased_counts, 25)))\n",
    "print('문장 tokens 개수 제 3 사분위: {}'.format(np.percentile(train_bert_token_cased_counts, 75)))\n",
    "print('문장 tokens 개수 99 퍼센트: {}'.format(np.percentile(train_bert_token_cased_counts, 99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.boxplot(train_bert_token_cased_counts,\n",
    "             labels=['counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_PATH = './gpt_ckpt/gpt2_kor_tokenizer.spiece'\n",
    "\n",
    "tokenizer = SentencepieceTokenizer(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentencepeice_counts = train_set.apply(lambda x:len(tokenizer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_sentencepeice_counts, bins=100, range=[0, 100], facecolor='r', density=True, label='train')\n",
    "plt.title('Normalised histogram of tokens count in sentence', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Number of tokens', fontsize=15)\n",
    "plt.ylabel('Prabability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('문장 tokens 개수 최대 값: {}'.format(np.max(train_sentencepeice_counts)))\n",
    "print('문장 tokens 개수 평균 값: {:.2f}'.format(np.mean(train_sentencepeice_counts)))\n",
    "print('문장 tokens 개수 표준편차: {:.2f}'.format(np.std(train_sentencepeice_counts)))\n",
    "print('문장 tokens 개수 중간 값: {}'.format(np.median(train_sentencepeice_counts)))\n",
    "print('문장 tokens 개수 제 1 사분위: {}'.format(np.percentile(train_sentencepeice_counts, 25)))\n",
    "print('문장 tokens 개수 제 3 사분위: {}'.format(np.percentile(train_sentencepeice_counts, 75)))\n",
    "print('문장 tokens 개수 99 퍼센트: {}'.format(np.percentile(train_sentencepeice_counts, 99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.boxplot(train_sentencepeice_counts,\n",
    "             labels=['counts'],\n",
    "             showmeans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "font_path = os.path.join(DATA_IN_PATH, 'NanumGothic.ttf')\n",
    "cloud = WordCloud(font_path = font_path, width=800, height=600).generate(\" \".join(train_set.astype(str)))\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.genre.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.filename.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.year.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.score.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
